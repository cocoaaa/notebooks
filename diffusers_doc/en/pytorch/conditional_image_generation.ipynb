{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EiPf2ky2T4c"
      },
      "source": [
        "# Conditional image generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyUe-sRL2T4d"
      },
      "source": [
        "Conditional image generation allows you to generate images from a text prompt. The text is converted into embeddings which are used to condition the model to generate an image from noise.\n",
        "\n",
        "The [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) is the easiest way to use a pre-trained diffusion system for inference.\n",
        "\n",
        "Start by creating an instance of [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) and specify which pipeline [checkpoint](https://huggingface.co/models?library=diffusers&sort=downloads) you would like to download.\n",
        "\n",
        "In this guide, you'll use [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) for text-to-image generation with [`runwayml/stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlJprvq62T4d"
      },
      "outputs": [],
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "model_name = \"stable-diffusion-v1-5\"\n",
        "\n",
        "generator = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M-h_jia2T4e"
      },
      "source": [
        "The [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) downloads and caches all modeling, tokenization, and scheduling components.\n",
        "Because the model consists of roughly 1.4 billion parameters, we strongly recommend running it on a GPU.\n",
        "You can move the generator object to a GPU, just like you would in PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFkTMp1X2T4e"
      },
      "outputs": [],
      "source": [
        "generator.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. generate celeba-like images from this model\n"
      ],
      "metadata": {
        "id": "3uc8SR0_3Ma1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = \"a face of a celebrity\"\n",
        "image_domain = 'celeba'\n",
        "n_samples = 16\n",
        "for i in range(n_samples):\n",
        "  image = generator(prompt).images[0]\n",
        "  image.save(f\"{model_name}_{image_domain}_{i}.png\")\n",
        "  print(f'done: {i}')"
      ],
      "metadata": {
        "id": "p3YKy0xd3PEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "w4ihqMwU3MSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l9VOE5xh3MJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6L4gVfl43L45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generate cifar10-like images from this model:\n",
        "- do generation for each label, by setting proper prompts"
      ],
      "metadata": {
        "id": "K72pNIyU3IsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image_domain = 'cifar10'\n",
        "cifar10_labels = ['car'] #todo\n",
        "n_samples = 16\n",
        "\n",
        "for label in cifar10_labels:\n",
        "  prompt = f'an image of {label}'\n",
        "  for i in range(n_samples):\n",
        "    image = generator(prompt).images[0]\n",
        "    image.save(f\"{model_name}_{image_domain}-{label}_{i}.png\")\n",
        "    print('done: {i}')\n",
        "\n"
      ],
      "metadata": {
        "id": "4BVl3P_s3ETm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qlpPUZcy3EGg"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}